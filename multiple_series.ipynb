{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast.utils import AirPassengersDF\n",
    "from statsforecast.models import AutoETS\n",
    "from statsforecast.utils import AirPassengers as ap\n",
    "from statsforecast.models import (\n",
    "    AutoARIMA, \n",
    "    SeasonalNaive,\n",
    "    AutoETS,\n",
    "    AutoCES,\n",
    "    AutoTheta,\n",
    "    ADIDA,\n",
    "    CrostonClassic, \n",
    "    IMAPA, \n",
    "    TSB,\n",
    "    GARCH,\n",
    "    ARCH\n",
    ")\n",
    "from utilsforecast.losses import mse\n",
    "from utilsforecast.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Conectar a la base de datos SQLite\n",
    "conexion = sqlite3.connect('C:\\\\Users\\\\uriel.lezama\\\\Desktop\\\\Nuevo SAEPyTEE\\\\datosSINE.db')\n",
    "\n",
    "# Definir la consulta SQL\n",
    "consulta = \"SELECT Fecha , [ConsumoCBO(M3)] FROM datosSINE WHERE Central='C T Punta Prieta' ORDER BY Fecha ASC \"\n",
    "\n",
    "# Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "df = pd.read_sql_query(consulta, conexion)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = 'ConsumoCBO(M3)'\n",
    "\n",
    "df[columna] = pd.to_numeric(df[columna], errors='coerce')\n",
    "\n",
    "# Añadir una columna 'unique_id'\n",
    "df['unique_id'] = range(1, len(df) + 1)\n",
    "df['unique_id'] = df['unique_id'].astype(float)\n",
    "\n",
    "# Convertir la columna 'Fecha' a formato de fecha\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "# Renombrar las columnas\n",
    "df.rename(columns={'Fecha': 'ds', columna: 'y'}, inplace=True)\n",
    "df['unique_id'] = 1.0\n",
    "\n",
    "# Imprimir la estructura del DataFrame\n",
    "df = df[['unique_id', 'ds', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Crear un DataFrame con todas las fechas\n",
    "fechas_completas = pd.date_range(start=df['ds'].min(), end=df['ds'].max(), freq='D')\n",
    "\n",
    "# Convertir fechas_completas a DataFrame\n",
    "df_fechas_completas = pd.DataFrame({'ds': fechas_completas})\n",
    "\n",
    "# Paso 2: Fusionar con el DataFrame original\n",
    "df = pd.merge(df_fechas_completas, df, on='ds', how='outer')\n",
    "\n",
    "# Paso 3: Rellenar valores faltantes de 'y' con ceros\n",
    "df['y'] = df['y'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = df\n",
    "StatsForecast.plot(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Calcular la autocorrelación de la serie temporal para lags múltiplos del período estacional (365 días)\n",
    "lags = range(1, 365*4, 365)  # Calcula la autocorrelación para lags\n",
    "plot_acf(df.y, lags=lags)  # Especifica los lags a considerar\n",
    "plt.xlabel('Lag (días)')\n",
    "plt.ylabel('Autocorrelación')\n",
    "plt.title('Autocorrelación de la Serie Temporal para Lags Anuales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "\n",
    "# Calcular la autocorrelación de la serie temporal para varios lags (por ejemplo, los primeros 365 días)\n",
    "lag_max = 365*4  # Establece el número máximo de lags para considerar\n",
    "lags = range(1, lag_max + 1)\n",
    "autocorrelation, conf_int = acf(df.y, nlags=lag_max, alpha=0.05)\n",
    "\n",
    "# Graficar la autocorrelación junto con los intervalos de confianza\n",
    "plt.bar(lags, autocorrelation[1:])\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelación')\n",
    "plt.title('Autocorrelación de la Serie Temporal para Lags Anuales')\n",
    "plt.axhline(y=0, color='gray', linestyle='--')  # Línea horizontal en y=0\n",
    "plt.axhline(y=conf_int[0][0], color='red', linestyle='--')  # Límite inferior del intervalo de confianza\n",
    "plt.axhline(y=conf_int[0][1], color='red', linestyle='--')  # Límite superior del intervalo de confianza\n",
    "plt.show()\n",
    "\n",
    "# Identificar los lags significativos (fuera del intervalo de confianza)\n",
    "significant_lags = [lags[i] for i in range(len(lags)) if autocorrelation[i] > conf_int[i][1] or autocorrelation[i] < conf_int[i][0]]\n",
    "print(\"Lags significativos:\", significant_lags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of models and instantiation parameters\n",
    "season_length = 365 # un año\n",
    "models = [\n",
    "    AutoARIMA(season_length = season_length),\n",
    "    SeasonalNaive(season_length=season_length),\n",
    "    AutoETS(season_length = season_length),\n",
    "    AutoCES(season_length = season_length),\n",
    "    AutoTheta(season_length = season_length),\n",
    "    ADIDA(), \n",
    "    CrostonClassic(), \n",
    "    IMAPA(), \n",
    "    TSB(alpha_d = 0.2, alpha_p = 0.2),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StatsForecast class as sf\n",
    "sf = StatsForecast( \n",
    "    models=models,\n",
    "    freq='D',  # 'M'\n",
    "    fallback_model = SeasonalNaive(season_length=season_length),\n",
    "    n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = sf.forecast(df=Y_df, h=season_length, level=[90])\n",
    "forecasts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot(Y_df,forecasts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to unique_ids and some selected models\n",
    "sf.plot(Y_df, forecasts_df, models=[\"AutoARIMA\",\"SeasonalNaive\"], unique_ids=[\"H10\", \"H105\"], level=[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvaldation_df = sf.cross_validation(\n",
    "    df=Y_df,\n",
    "    h=season_length,\n",
    "    step_size=season_length,\n",
    "    n_windows=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(df, metric):\n",
    "    models = df.drop(columns=['unique_id', 'ds', 'cutoff', 'y']).columns.tolist()\n",
    "    evals = []\n",
    "    # Calculate loss for every unique_id and cutoff.    \n",
    "    for cutoff in df['cutoff'].unique():\n",
    "        eval_ = evaluate(df[df['cutoff'] == cutoff], metrics=[metric], models=models)\n",
    "        evals.append(eval_)\n",
    "    evals = pd.concat(evals)\n",
    "    evals = evals.groupby('unique_id').mean(numeric_only=True) # Averages the error metrics for all cutoffs for every combination of model and unique_id\n",
    "    evals['best_model'] = evals.idxmin(axis=1)\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = evaluate_cross_validation(crossvalidation_df, mse)\n",
    "evaluation_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
